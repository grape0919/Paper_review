***
### 읽기전 알아야하는 기술들

> - Word Embedding
- word piece model
- rnn
- encoding - decoding
- seq2seq
- attention mechanism
- transformer
- multi-head self attention
- BERT
- Vanila LayoutLM

***





# LayoutLM


# LayoutLMv2





